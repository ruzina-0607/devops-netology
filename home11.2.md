## Домашнее задание к занятию «Микросервисы: принципы»
-------
### Задача 1: API Gateway
|ПО|Возможности|Вывод|
|--|-----------|-----|
|Amazon API Gateway|Облачный. Выставляется как сервис, предназначенный для создания, публикации, обслуживания, мониторинга и обеспечения безопасности API в любых масштабах. С одной стороны мы не можем его расширять функционально, а с другой стороны он заинтегрирован со всей инфраструктурой AWS. Он подключается к мониторингу, AWS CloudWatch, что позволяет контролировать, отслеживать и управлять количеством запросов. Он подключается к API Gateway Cache (отдельный сервис), что позволяет легко настраивать route и тд. Из его плюсов можно выделить следующее: - Создание API RESTful при помощи API HTTP или API REST. - Интерфейсы API WebSocket для разработки приложений, которым требуется двусторонняя связь в режиме реального времени. - Частная интеграция с AWS ELB и AWS Cloud Map. - Ключи API для сторонних разработчиков. - Генерирование клиентских SDK на многих языках, включая JavaScript, iOS и Android. - Внедрение подписи четвёртой версии для API REST и API WebSocket при авторизации и проверке запросов API к другим сервисам AWS API Gateway. - Авторизация с помощью AWS Lambda.|Считаю, что необходимо выбрать данное ПО. 1. Шлюз API создает API-интерфейсы WebSocket, которые: используют веб-сокет протокол, обеспечивающий полнодуплексную связь между клиентом и сервером с отслеживанием состояния. Присутствует маршрутизация входящих сообщений на основе содержимого сообщения. 2. Используются мощные и гибкие механизмы аутентификации, такие как AWS Identity and Access Management, функции авторизации Lambda и пулы пользователей Amazon Cognito. 3. Все API, созданные с помощью сервиса Amazon API Gateway, поддерживают только конечные точки HTTPS. По умолчанию Amazon API Gateway назначает для API внутренний домен, который автоматически использует сертификат сервиса Amazon API Gateway. Настраивая API для работы под другим доменным именем, вы можете предоставить для домена собственный сертификат.|
|NGINX Plus| платформа на базе HTTP-сервера, созданная с использованием модели Open Core и предназначенная для балансировки нагрузки сайтов с высоким трафиком. Особенности использования следующие: Проверка работоспособности приложений (контроль за сбоями в работе бэкендов). Мониторинг активности с экспортом метрик производительности через JSON. Метрики могут забираться в режиме реального времени и использоваться во внешних системах мониторинга для слежения и визуализации изменения производительности. Расширенные средства балансировки нагрузки, позволяющие определять сложные правила балансировки при распределении запросов пользователей. Динамическая реконфигурация на лету, предоставляющая простой HTTP API для изменения маршрутов обработки запросов без перезапуска серверного процесса (полезно для организации работы облачных систем без фиксированной структуры). Расширенные возможности по ведению логов (возможность отправки логов на удаленный централизованный сервер сбора логов с использованием протокола syslog). Настройки для обеспечения высокой доступности. Адаптивное потоковое вещание мультимедиа контента. Поддерживается потоковая доставка видео в форматах MP4, FLV, Adobe HDS и Apple HLS с возможностью адаптивного изменения битрейта в зависимости от параметров канала связи каждого клиента. Комплексная защита сайтов и приложений, трафика HTTP, TCP и UDP, контроль доступа и уязвимых ресурсов. Возможность обрабатывать сотни тысяч клиентов одновременно и обслуживать сотни тысяч ресурсов в секунду. Конфигурирование и тюнинг (анализ архитектуры, выявление узких мест, рекомендации по улучшению настроек, рецензирование логов и т.п.). Оптимизация производительности (тестирование производительности, симуляция пиковых нагрузок, рекомендации по оптимизации). Управление техническими аккаунтами (планирование и технический аудит, планирование развития и прием рекомендаций по реализации в nginx новых возможностей).|-|
|Spring cloud gateway|Это отдельное Spring Boot приложение, через которое проходят все запросы, реализация шаблона Reverse Proxy. Прокси, в свою очередь, анализирует запрос, перенаправляет его к нужному микросервису и возвращает ответ обратно. Можно зафиксировать REST API на прокси и менять внутреннюю структуру как угодно. Снаружи ничего не поменяется, просто прокси будет обращаться по другим адресам. А обращения к самому прокси останутся прежними. Возможности Spring Cloud Gateway: Построен на Spring Framework 5, Project Reactor и Spring Boot 2.0. Возможность сопоставления маршрутов по любому атрибуту запроса. Предикаты и фильтры специфичны для маршрутов. Интеграция с Circuit Breaker. Интеграция Spring Cloud DiscoveryClient. Легко писать предикаты и фильтры. Ограничение скорости запросов. Переписывание пути.|-|
|Netflix Zuul|Это основанный на JVM маршрутизатор и серверный балансировщик нагрузки от Netflix. Используется с аннотацией @EnableZuulProxy. Zuul автоматически выберет список серверов в Eureka. Он хорошо работает в связке с Hystrix, Ribbon и Turbine. Он запускает предварительные фильтры (pre-filters), затем передает запрос с помощью клиента Netty, а затем возвращает ответ после запуска постфильтров (post-filters). Фильтры являются основой функциональности Zuul. Они могут выполняться в разных частях жизненного цикла “запрос-ответ”, т.к. они отвечают за бизнес-логику приложения и могут выполнять самые разные задачи.|-|


### Задача 2: Брокер сообщений
|ПО|Возможности|Вывод|
|--|-----------|-----|
|RabbitMQ|Брокер сообщений, основанный на протоколе AMQP, Advanced Message Queuing Protocol. Это открытый протокол передачи сообщений, который нужен для общения разных частей системы между собой. Плюсы RabbitMQ: Лёгкость разработки. У RabbitMQ есть библиотеки клиента для большинства современных языков и открытый исходный код, чтобы в нём разбираться. Простое администрирование. У RabbitMQ удобная админка, где вы можете в режиме реального времени разбираться с тем, что происходит. Роутинги можно настраивать в процессе, переключая нагрузку и меняя правила обработки. Тонкая настройка. Многие параметры можно менять, чтобы подстроить систему под свои нужды. Особенно это касается очередей. Можно смело использовать RabbitMQ когда важна гибкость маршрутизации сообщений внутри системы. В таком случае он предоставляет инструменты для построения путей доставки данных и способен решить самые хитрые сценарии в организации потоков событий, а также если вам важен сам факт доставки сообщений и порядок их получения.|-|
|Apache Kafka|Концептуально в Kafka нет многообразия конфигураций, сложных механизмов распределения сообщений по очередям и процесса доставки каждого отдельного сообщения. Ядро его функциональности — запись данных, хранение их в течение заданного времени и выдача этих данных по запросу. В Kafka данные физически хранятся на диске в виде партиций. Новые сообщения добавляются в commit log. Они помещаются строго в конец, и их порядок после этого не меняется, благодаря чему в каждой отдельной партиции сообщения всегда расположены в порядке их добавления. Само сообщение с точки зрения Kafka — просто набор байт, хранящийся в ячейке партиции под индексом с названием offset. Содержимое и структура не имеют значения для Kafka. Сообщение может содержать ключ, также представляющий из себя набор байт. Ключ позволяет получить больше контроля над механизмом распределения сообщений по партициям. Функцию очереди в Kafka выполняет topic, который нужен для объединения нескольких партиций в общий поток. Таким образом сообщение, которое относится к одному топику, может храниться в двух разных партициях, из которых Consumer вытаскивает их по запросу. Плюсы Kafka: Делает всего две вещи: записывает и отдаёт. Если использовать брокер вместе с надкластером ZooKeeper, то можно наладить кластерные трансферы. Пропускная способность — миллионы сообщений в секунду. Причём её можно эффективно наращивать: добавить датчик в кластер и при переполнении просто создавать новый, настраивая между ними репликацию. Позволяет перечитывать сообщения. Позволяет читать сообщения пачками. Можно запросить сразу 1000 сообщений, что снижает нагрузку на сеть. Минусы Kafka: Проблемы с обработкой битых сообщений. В Kafka для обработки следующего сообщения нам нужно обработать его или пропустить текущее. В Kafka для этого применяют концепцию dead letter queue — отдельного места для сохранения битых сообщений. Нужно вести учёт последнего прочитанного сообщения, причём для каждого читателя. Потому что данные неизменны, и мы раскидываем не их, а читателей по одному и тому же массиву данных. То есть храним те точки, где они остановились в чтении. Для этого есть несколько решений, но все они, конечно, утяжеляют систему. Использовать Kafka нужно при конвейерной обработке данных. Kafka хорошо работает как общая шина для нескольких сервисов. Сервис что-то сделал, записал результат, следующий по конвейеру считал — записал, и так далее. При Event-driven architecture. В этом случае сообщения можно бродкастить всем необходимым сервисам, и нужные адресаты их получат. При использовании буфера для логов и метрик. Промежуточное хранилище для большого количества данных, где они будут сохранны и упорядочены. В Kafka используется pull-, а не push-механизм. В RabbitMQ сообщения загружаются в читателей, а в Kafka они приходят сами и берут, что нужно. Чтобы начать читать сообщения с произвольного места в очереди, Consumer сообщает брокеру номер сообщения и номер партиции. Процесс чтения сообщений аналогичен проходу по массиву: Consumer получает их одно за другим, слева направо. Данные персистентны: они лежат в партиции нужное вам время, пока остаются актуальны или хватает места на диске. Персистентность позволяет заново использовать данные и читать их пачками, что полезно для пропускной способности сети. |Выбираю данный брокер. 1) Поддерживает кластеризацию (подробнее в описании ПО). 2) В Kafka данные физически хранятся на диске в виде партиций. 3) Пропускная способность — миллионы сообщений в секунду. Причём её можно эффективно наращивать: добавить датчик в кластер и при переполнении просто создавать новый, настраивая между ними репликацию. 4) Kafka поддерживает не только JSON, но и другие форматы сообщений: бинарные Apache AVRO и Protobuf, текст и т.д. 5) Для разделения прав доступа можно использовать следующий стек: Kafka Security Manager (по топикам), kafka-minion exporter, который позволяет получать больше информации о том, что происходит с топиками. Для просмотра содержимого с сервера Kafka можно использовать Kafdrop. 6) Исходя из начала описания, Kafka очень проста в использовании.|
|Amazon Simple Queue Service (SQS)|Управляемый сервис очередей сообщений, с помощью которого можно так же, как и с помощью других брокеров, изолировать и масштабировать микросервисы и бессерверные приложения. SQS работает в связке с SNS — сервисом обмена сообщениями для связи между приложениями, а также между приложениями и пользователями. Обмен происходит по модели pub-sub («издатель — подписчик»): получатели подписываются на тему (топик), а издатель публикует в эту тему сообщения, которые может считывать множество получателей. AWS устанавливает некоторые ограничения SQS и SNS: Лимит на отправленные сообщения. Это те сообщения в SQS, которые были получены потребителем, но ещё не были удалены. Каждая очередь SQS ограничена 120 000 сообщениями — или 20 000, если это очередь FIFO. Лимит на размер сообщения. Атрибут максимального размера сообщения в очереди определяет размер сообщений, поступающих в очередь. Сообщения, превышающие лимит, отклоняются, поэтому превысить лимит фактически невозможно. Лимит на пропускную способность очереди FIFO. Очереди FIFO могут поддерживать только 300 операций отправки, получения или удаления в секунду. При использовании пакетной обработки 10 сообщений производительность увеличивается до 3000 операций в секунду.|-|



