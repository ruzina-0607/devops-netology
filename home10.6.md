## Домашнее задание к занятию 17 «Инцидент-менеджмент»
---
### Основная часть
Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

### Ответ
|Шаг|Описание|
|---|--------|
|Краткое описание инцидента|В 22:52 (21.10.18) по UTC на нескольких сервисах GitHub.com пострадали несколько сетевых разделов и последующим сбоем базы данных, что привело к появлению непоследовательной информации на GitHub веб-сайте.|
|Что было сделано||
|Причина|21 октября в 22:52 UTC в результате регламентных работ по замене вышедшего из строя оптического оборудования 100G была потеряна связь между сетевым концентратором и основным центром обработки данных. |
|Воздействие|Никакие пользовательские данные не были потеряны. В течение большей части инцидента GitHub не мог обслуживать события webhook или создавать и публиковать сайты GitHub Pages. Инцидент повлиял только на метаданные веб-сайтов, хранящиеся в наших базах данных MySQL, такие как Issue и PR. Данные репозитория Git остаются неизменными и доступны на протяжении всего инцидента.|
|Обнаружение||
|Реакция||
|Восстановление||
|Таймлайн| 22:52 - плановые работы по тех обслуживанию; 
22:52 - Raft начал процесс отмены выбора руководства. Центр обработки данных и узлы Orchestrator общедоступного облака смогли установить кворум и начать аварийное переключение кластеров для направления операций записи в центр обработки данных. Orchestrator приступил к организации топологии кластера базы данных. Когда подключение было восстановлено, уровень приложений начал направлять трафик записи на новые первичные серверы на сайте West Coast. Серверы баз данных содержали короткий период записи, который не был реплицирован на объект. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали записи, которых не было в другом центре обработки данных, GitHub не смогли безопасно выполнить возврат основного сервера в центр обработки данных.
22:54 - Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои системах. В это время несколько инженеров отвечали и работали над сортировкой входящих уведомлений. 
23:02 - инженеры группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. Запрос API Orchestrator показал топологию репликации базы данных, которая включала только серверы из центра обработки данных.
23:07 - команда решила вручную заблокировать внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений.
23:09 - команда реагирования перевела сайт в желтый статус. Это действие автоматически превратило ситуацию в активный инцидент и отправило предупреждение координатору инцидента. 
23:11 - координатор инцидента присоединился и через две минуты изменил статус решения на красный.|
|Последующие действия||








